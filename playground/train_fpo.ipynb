{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84e0eb90-cfa6-4627-b08e-949a48561ccf",
   "metadata": {},
   "source": [
    "# FPO on MuJoCo Playground\n",
    "\n",
    "We begin with imports and JAX compilation caching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d039154-092a-49e8-ac5d-f10ac96a2e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: MUJOCO_GL=egl\n",
      "env: XLA_PYTHON_CLIENT_PREALLOCATE=false\n",
      "env: CUDA_VISIBLE_DEVICES=2\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%env MUJOCO_GL=egl\n",
    "%env XLA_PYTHON_CLIENT_PREALLOCATE=false\n",
    "%env CUDA_VISIBLE_DEVICES=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa0d7563-4698-435a-a5d8-4eed60a694c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use JAX with compilation cache.\n",
    "import jax\n",
    "jax.config.update(\"jax_compilation_cache_dir\", \"/tmp/jax_cache\")\n",
    "jax.config.update(\"jax_persistent_cache_min_entry_size_bytes\", -1)\n",
    "jax.config.update(\"jax_persistent_cache_min_compile_time_secs\", 0)\n",
    "jax.config.update(\n",
    "    \"jax_persistent_cache_enable_xla_caches\", \"xla_gpu_per_fusion_autotune_cache_dir\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ca79432-0306-4284-91a5-811108548a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flow_policy import fpo, rollouts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7dc538-4d3e-41f2-9410-a964709f622c",
   "metadata": {},
   "source": [
    "## Load configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d99666b-4b6d-49a6-adc4-c4c8105815a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mujoco_playground import registry\n",
    "\n",
    "# Load environment and default FPO config.\n",
    "env_name = \"CheetahRun\"\n",
    "env = registry.load(env_name)\n",
    "env_cfg = registry.get_default_config(env_name)\n",
    "config = fpo.FpoConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd5291b-3994-48d0-bf0a-e39f3a8cc85e",
   "metadata": {},
   "source": [
    "## Initialize training state and environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a073fce0-333e-4900-8b5c-68582332a9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_state = fpo.FpoState.init(prng=jax.random.key(42), env=env, config=config)\n",
    "rollout_state = rollouts.BatchedRolloutState.init(\n",
    "    env,\n",
    "    prng=jax.random.key(42),\n",
    "    num_envs=config.num_envs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b0b6e5-c065-43ba-88a8-f61fb5b27fe0",
   "metadata": {},
   "source": [
    "## FPO training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "700a5651-ec1d-4903-8fad-d2aa67e7ac74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval metrics at FPO step 0/61:\n",
      "  Reward: 21.68 +/- 4.52\n",
      "Eval metrics at FPO step 6/61:\n",
      "  Reward: 284.23 +/- 31.72\n",
      "Eval metrics at FPO step 13/61:\n",
      "  Reward: 581.11 +/- 16.62\n",
      "Eval metrics at FPO step 20/61:\n",
      "  Reward: 700.04 +/- 117.06\n",
      "Eval metrics at FPO step 26/61:\n",
      "  Reward: 753.22 +/- 100.79\n",
      "Eval metrics at FPO step 33/61:\n",
      "  Reward: 808.30 +/- 95.87\n",
      "Eval metrics at FPO step 40/61:\n",
      "  Reward: 869.48 +/- 60.77\n",
      "Eval metrics at FPO step 46/61:\n",
      "  Reward: 857.08 +/- 41.23\n",
      "Eval metrics at FPO step 53/61:\n",
      "  Reward: 784.28 +/- 132.16\n",
      "Eval metrics at FPO step 60/61:\n",
      "  Reward: 877.80 +/- 52.56\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as onp\n",
    "\n",
    "outer_iters = config.num_timesteps // config.iterations_per_env // config.num_envs\n",
    "eval_iters = set(onp.linspace(0, outer_iters - 1, config.num_evals, dtype=int))\n",
    "for i in range(outer_iters):\n",
    "    # Rollout + inner training loop.\n",
    "    rollout_state, transitions = rollout_state.rollout(\n",
    "        agent_state,\n",
    "        episode_length=config.episode_length,\n",
    "        iterations_per_env=config.iterations_per_env,\n",
    "    )\n",
    "    agent_state, metrics = agent_state.training_step(transitions)\n",
    "\n",
    "    # Print eval metrics.\n",
    "    if i in eval_iters:\n",
    "        eval_outputs = rollouts.eval_policy(\n",
    "            agent_state,\n",
    "            prng=jax.random.fold_in(agent_state.prng, i),\n",
    "            num_envs=128,\n",
    "            max_episode_length=config.episode_length,\n",
    "        )\n",
    "        s_np = {k: onp.array(v) for k, v in eval_outputs.scalar_metrics.items()}\n",
    "        print(f\"Eval metrics at FPO step {i}/{outer_iters}:\")\n",
    "        print(\n",
    "            f\"  Reward: {s_np['reward_mean']:.2f} +/- {s_np['reward_std']:.2f}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd07b39-885b-4217-af4f-376ad07519c0",
   "metadata": {},
   "source": [
    "## Render rollouts from trained policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d03f29a-57eb-4bd7-bcaf-30516f2a284c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapy as media\n",
    "from jax import numpy as jnp\n",
    "import random\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "jit_act = jax.jit(type(agent_state).sample_action, static_argnums=(3,))\n",
    "jit_step = jax.jit(env.step)\n",
    "jit_reset = jax.jit(env.reset)\n",
    "\n",
    "def render_and_show() -> None:\n",
    "    rng = jax.random.key(random.randint(0, 10_000))\n",
    "    \n",
    "    rollout = []\n",
    "    n_episodes = 1\n",
    "    render_every = 1\n",
    "    \n",
    "    for _ in range(n_episodes):\n",
    "        state = jit_reset(rng)\n",
    "        rollout.append(state)\n",
    "        for i in tqdm(range(100)):\n",
    "            act_rng, rng = jax.random.split(rng)\n",
    "            ctrl, _ = jit_act(agent_state, state.obs, act_rng, deterministic=False)\n",
    "            state = jit_step(state, jnp.tanh(ctrl))\n",
    "            rollout.append(state)\n",
    "            \n",
    "    frames = env.render(rollout[::render_every], height=480, width=640)\n",
    "    media.show_video(frames, fps=1.0 / env.dt / render_every)\n",
    "    media.write_video(\"fpo_rollout.mp4\", frames, fps=1.0 / env.dt / render_every)\n",
    "    print(\"Wrote to fpo_rollout.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befd6fdb-594c-4664-bb5b-b44749dd5430",
   "metadata": {},
   "outputs": [],
   "source": [
    "render_and_show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad330f1-7b70-4bb6-befc-75511b0ab6d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
